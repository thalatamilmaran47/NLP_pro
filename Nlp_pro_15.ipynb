{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOL4Y7ub8acH2JKWlSoOuu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thalatamilmaran47/NLP_pro/blob/main/Nlp_pro_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6coAiA-3hIs",
        "outputId": "05bb2e94-eae1-4024-8dbf-e785ac75168a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Natural Language Processing (NLP) is a field of Artificial Intelligence \n",
            "that focuses on the interaction between computers and humans using natural language. NLP is widely \n",
            "used in applications such as chatbots, search engines, text summarization, and sentiment analysis.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import heapq\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import string\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "\n",
        "# Input text\n",
        "text = \"\"\"Natural Language Processing (NLP) is a field of Artificial Intelligence\n",
        "that focuses on the interaction between computers and humans using natural language.\n",
        "It helps machines understand, interpret, and generate human language. NLP is widely\n",
        "used in applications such as chatbots, search engines, text summarization, and sentiment analysis.\"\"\"\n",
        "\n",
        "# Tokenize sentences and words\n",
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text.lower())\n",
        "\n",
        "# Remove stopwords and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [\n",
        "    word for word in words\n",
        "    if word not in stop_words and word not in string.punctuation\n",
        "]\n",
        "\n",
        "# Calculate word frequency\n",
        "word_freq = {}\n",
        "for word in filtered_words:\n",
        "    word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "# Score sentences\n",
        "sentence_scores = {}\n",
        "for sentence in sentences:\n",
        "    for word in word_tokenize(sentence.lower()):\n",
        "        if word in word_freq:\n",
        "            sentence_scores[sentence] = sentence_scores.get(sentence, 0) + word_freq[word]\n",
        "\n",
        "# Select top sentences for summary\n",
        "summary_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "# Display summary\n",
        "summary = \" \".join(summary_sentences)\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ]
    }
  ]
}